{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5aa5cf-e95b-45ae-9795-0eb1df2d6ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ”¹ Ridge Regression (L2 Regularization)\\n\\nDefinition: Ridge Regression is a type of Linear Regression that includes a penalty term (L2 regularization) to shrink coefficients.\\n\\n\\u200bThe penalty reduces the impact of less important features, preventing overfitting.\\n\\nCoefficients become smaller but never exactly zero.\\n\\nðŸ‘‰ Good when you have multicollinearity (correlated features) or want to reduce model complexity.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ðŸ”¹ Ridge Regression (L2 Regularization)\n",
    "\n",
    "Definition: Ridge Regression is a type of Linear Regression that includes a penalty term (L2 regularization) to shrink coefficients.\n",
    "\n",
    "â€‹The penalty reduces the impact of less important features, preventing overfitting.\n",
    "\n",
    "Coefficients become smaller but never exactly zero.\n",
    "\n",
    "ðŸ‘‰ Good when you have multicollinearity (correlated features) or want to reduce model complexity.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb382930-246b-4578-99a8-41c6ba29e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression Example with Prediction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "X = df.drop(\"MedHouseVal\", axis=1)\n",
    "y = df[\"MedHouseVal\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Ridge Regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"ðŸ”¹ Ridge Regression\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_ridge))\n",
    "print(\"Accuracy (RÂ² Score): {:.2f}%\".format(r2_score(y_test, y_pred_ridge) * 100))\n",
    "\n",
    "# Custom prediction (example: first row of test data)\n",
    "sample = X_test.iloc[0:1]\n",
    "sample_scaled = scaler.transform(sample)\n",
    "prediction = ridge_model.predict(sample_scaled)\n",
    "print(\"\\nCustom Input Prediction (Ridge):\", prediction[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
